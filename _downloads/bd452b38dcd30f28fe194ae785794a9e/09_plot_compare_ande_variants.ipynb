{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Data Efficiency & Complexity: Generative vs. Hybrid Levels (L1-L4)\n\nThis experiment compares the full hierarchy of parameter granularity in ALR.\n\n**Models Compared:**\n1.  **AnDE (Generative):** Baseline. No weights.\n2.  **ALR Level 1 (Model):** 1 weight per SPODE. (Low Variance).\n3.  **ALR Level 2 (Value):** 1 weight per SPODE per Parent Value. (High Variance).\n4.  **ALR Level 3 (Class):** 1 weight per SPODE per Class. (Balanced).\n5.  **ALR Level 4 (Val+Cls):** 1 weight per SPODE per Parent Value per Class. (Max Variance).\n\n**Observations:**\n-   **Small N (~200):** AnDE (Generative) leads due to better calibration. Hybrids may overfit.\n-   **Medium N (~500):** ALR (Hybrid) catches up.\n-   **Large N (>5000):** Higher granularity wins. Order: L1 < L2 < L3 < L4.\n-   **Time:** L4 is significantly slower due to larger optimization space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: The scikit-bayes Developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.ticker import ScalarFormatter\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.model_selection import train_test_split\n\nfrom skbn.ande import ALR, AnDE\n\n# Setup\nseeds = [1, 2, 3, 42, 123]\n# Full range of sizes to see the crossover\nsizes = [100, 500, 1000, 5000, 10000, 20000]\n\nmodels_config = [\n    (\"AnDE (Gen)\", lambda: AnDE(n_dependence=1, n_jobs=-1)),\n    (\n        \"ALR L1 (Model)\",\n        lambda: ALR(n_dependence=1, weight_level=1, l2_reg=1e-3, n_jobs=-1),\n    ),\n    (\n        \"ALR L2 (Value)\",\n        lambda: ALR(n_dependence=1, weight_level=2, l2_reg=1e-3, n_jobs=-1),\n    ),\n    (\n        \"ALR L3 (Class)\",\n        lambda: ALR(n_dependence=1, weight_level=3, l2_reg=1e-3, n_jobs=-1),\n    ),\n    (\n        \"ALR L4 (Val+Cls)\",\n        lambda: ALR(n_dependence=1, weight_level=4, l2_reg=1e-3, n_jobs=-1),\n    ),\n]\n\n# Results storage: [seed, size, model]\nn_models = len(models_config)\nres_ll = np.zeros((len(seeds), len(sizes), n_models))\nres_acc = np.zeros((len(seeds), len(sizes), n_models))\nres_time = np.zeros((len(seeds), len(sizes), n_models))\n\nprint(\"Running benchmark with all 4 granularity levels...\")\n\nfor i, seed in enumerate(seeds):\n    # Using a slightly larger dataset to ensure we have enough for the biggest train split\n    X, y = make_classification(\n        n_samples=30000, n_features=10, n_informative=8, random_state=seed\n    )\n\n    for j, n_train in enumerate(sizes):\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, train_size=n_train, test_size=5000, random_state=seed\n        )\n\n        for k, (name, factory) in enumerate(models_config):\n            clf = factory()\n\n            start = time.time()\n            clf.fit(X_train, y_train)\n            res_time[i, j, k] = time.time() - start\n\n            # Use predict_proba for both metrics to save one inference pass if wanted,\n            # but predict() is safer for accuracy consistency.\n            y_prob = clf.predict_proba(X_test)\n            y_pred = clf.predict(X_test)\n\n            res_ll[i, j, k] = log_loss(y_test, y_prob)\n            res_acc[i, j, k] = accuracy_score(y_test, y_pred)\n\n        print(f\"Seed {seed}, N={n_train} done.\")\n\n# Average\nmean_ll = res_ll.mean(axis=0)\nmean_acc = res_acc.mean(axis=0)\nmean_time = res_time.mean(axis=0)\n\n# --- Visualization ---\nfig, axes = plt.subplots(1, 3, figsize=(22, 6), layout=\"constrained\")\n\n# Define Colors:\n# AnDE gets a unique cool color.\n# ALR levels get a warm sequential gradient (Light Orange -> Dark Red/Brown)\ncmap = plt.cm.Oranges\n# Generate 4 colors from the colormap, starting from 0.4 to avoid too light colors\nalr_colors = [cmap(x) for x in np.linspace(0.4, 1.0, 4)]\ncolors = [\"royalblue\"] + alr_colors\n\n# Markers: Distinct shapes\nmarkers = [\"o\", \"s\", \"D\", \"^\", \"v\"]\n\nfor k, (name, _) in enumerate(models_config):\n    # Plot 1: Log Loss\n    axes[0].plot(\n        sizes,\n        mean_ll[:, k],\n        marker=markers[k],\n        label=name,\n        color=colors[k],\n        lw=2,\n        markersize=6,\n    )\n    # Plot 2: Accuracy\n    axes[1].plot(\n        sizes,\n        mean_acc[:, k],\n        marker=markers[k],\n        label=name,\n        color=colors[k],\n        lw=2,\n        markersize=6,\n    )\n    # Plot 3: Training Time\n    axes[2].plot(\n        sizes,\n        mean_time[:, k],\n        marker=markers[k],\n        label=name,\n        color=colors[k],\n        lw=2,\n        markersize=6,\n    )\n\n# --- Formatting ---\n\n# Panel 1: Log Loss\naxes[0].set_ylabel(\"Test Log Loss (Lower is Better)\", fontsize=12)\naxes[0].set_title(\"Probability Calibration (Log Loss)\", fontsize=14, pad=10)\n\n# Panel 2: Accuracy\naxes[1].set_ylabel(\"Test Accuracy (Higher is Better)\", fontsize=12)\naxes[1].set_title(\"Classification Accuracy\", fontsize=14, pad=10)\n\n# Panel 3: Time\naxes[2].set_ylabel(\"Training Time (s)\", fontsize=12)\naxes[2].set_title(\"Computational Cost\", fontsize=14, pad=10)\naxes[2].set_yscale(\"log\")\n\n# Common formatting for all subplots\nfor ax in axes:\n    ax.set_xlabel(\"Training Set Size (log scale)\", fontsize=12)\n    ax.set_xscale(\"log\")\n    ax.grid(True, which=\"major\", ls=\"-\", alpha=0.3)\n    ax.legend(fontsize=10, loc=\"best\")\n\n    # --- FIX: Readable X-Axis Labels ---\n    # 1. Force matplotlib to use exactly our dataset sizes as ticks\n    ax.set_xticks(sizes)\n\n    # 2. Format as plain integers (e.g., 100, 500) instead of scientific (1e2)\n    ax.get_xaxis().set_major_formatter(ScalarFormatter())\n\n    # 3. Rotate labels to prevent horizontal overlapping\n    ax.set_xticklabels(sizes, rotation=45, ha=\"right\")\n\n    # 4. Remove minor ticks to clean up the log-scale look\n    ax.minorticks_off()\n\n# Global Title\nfig.suptitle(\n    \"Granularity Trade-off: Full Hierarchy (L1-L4) vs Generative (n=1)\", fontsize=18\n)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}