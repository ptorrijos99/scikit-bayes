{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MixedNB Equivalence with CategoricalNB\n\nThis example demonstrates that :class:`skbn.mixed_nb.MixedNB`\nproduces identical results to :class:`sklearn.naive_bayes.CategoricalNB`\nwhen all features are discrete (categorical).\n\nThe plot shows the decision boundaries for both classifiers. As expected,\nthe boundaries are identical, and the predicted probabilities for the\ndataset are all-close.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: The scikit-bayes Developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom numpy.testing import assert_allclose\nfrom sklearn.naive_bayes import CategoricalNB\n\nfrom skbn.mixed_nb import MixedNB\n\n# 1. Generate a 2D Categorical dataset (3 categories for f0, 4 for f1)\nnp.random.seed(42)\nn_samples = 150\nX = np.zeros((n_samples, 2), dtype=int)\nX[:, 0] = np.random.randint(0, 3, size=n_samples)\nX[:, 1] = np.random.randint(0, 4, size=n_samples)\n# Logic: Interaction between categories\ny = (X[:, 0] + X[:, 1] >= 3).astype(int)\n\n# 2. Fit both classifiers\ncnb = CategoricalNB(alpha=1.0)\ncnb.fit(X, y)\nprobs_cnb = cnb.predict_proba(X)\n\n# MixedNB will auto-detect both features as 'categorical'\nmnb = MixedNB(alpha=1.0)\nmnb.fit(X, y)\nprobs_mnb = mnb.predict_proba(X)\n\n# 3. Assert equivalence\ntry:\n    assert_allclose(probs_cnb, probs_mnb, rtol=1e-7, atol=1e-7)\n    equivalence_message = \"Probabilities are identical.\"\nexcept AssertionError as e:\n    equivalence_message = f\"Probabilities are NOT identical:\\n{e}\"\n\nprint(f\"CategoricalNB vs MixedNB Equivalence Check: {equivalence_message}\")\n\n# 4. Plot decision boundaries\nfig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\nmodels = [cnb, mnb]\ntitles = [\"1. scikit-learn CategoricalNB\", \"2. skbn MixedNB (auto-detected)\"]\n\n# Define grid for visualization (Centers for prediction, Edges for plotting)\n# Feature 0: Categories 0, 1, 2\nx_centers = np.arange(3)\nx_edges = np.arange(4) - 0.5\n\n# Feature 1: Categories 0, 1, 2, 3\ny_centers = np.arange(4)\ny_edges = np.arange(5) - 0.5\n\n# Create prediction grid (Integer combinations)\nxx, yy = np.meshgrid(x_centers, y_centers)\ngrid_pred = np.c_[xx.ravel(), yy.ravel()]\n\nfor ax, model, title in zip(axes, models, titles):\n    # Predict probabilities on integer grid\n    probs = model.predict_proba(grid_pred)[:, 1]\n    Z = probs.reshape(xx.shape)\n\n    # Plot Heatmap - VIRIDIS\n    # Using pcolormesh with edges defines the \"blocks\" perfectly\n    ax.pcolormesh(\n        x_edges,\n        y_edges,\n        Z,\n        cmap=\"viridis\",\n        vmin=0,\n        vmax=1,\n        shading=\"flat\",\n        alpha=0.8,\n        edgecolors=\"none\",\n    )\n\n    # Overlay real data points with consistent style\n    # Jitter points slightly to show density\n    x_jit = X[:, 0] + np.random.uniform(-0.2, 0.2, size=n_samples)\n    y_jit = X[:, 1] + np.random.uniform(-0.2, 0.2, size=n_samples)\n\n    # Class 0 -> Indigo Circle\n    ax.scatter(\n        x_jit[y == 0],\n        y_jit[y == 0],\n        c=\"indigo\",\n        marker=\"o\",\n        s=40,\n        alpha=0.8,\n        edgecolors=\"w\",\n        linewidth=0.8,\n        label=\"Class 0\",\n    )\n\n    # Class 1 -> Gold Triangle\n    ax.scatter(\n        x_jit[y == 1],\n        y_jit[y == 1],\n        c=\"gold\",\n        marker=\"^\",\n        s=40,\n        alpha=0.9,\n        edgecolors=\"k\",\n        linewidth=0.5,\n        label=\"Class 1\",\n    )\n\n    ax.set_title(title, fontsize=12)\n    ax.set_xlabel(\"Feature 0 (Categorical)\")\n    ax.set_xticks(x_centers)\n    ax.set_yticks(y_centers)\n    ax.grid(True, alpha=0.2, linestyle=\"--\")\n\naxes[0].set_ylabel(\"Feature 1 (Categorical)\")\naxes[0].legend(loc=\"lower right\")\n\nfig.suptitle(\"Equivalence of MixedNB and CategoricalNB on Discrete Data\", fontsize=16)\nplt.tight_layout()\nplt.subplots_adjust(top=0.85)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}